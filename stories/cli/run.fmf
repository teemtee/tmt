story: 'As a user I want to execute tests easily'

/default:
    story: 'Default should cover the most common use case'
    description:
        Run all relevant tests on the default environment.
        Default environment should be something safe which
        should not modify user environment. Perhaps something
        like 'x86_64 virtual machine from the testing farm'?
    implemented: /tmt/base.py
    example: tmt run

/select:
    story: 'Select multiple steps to be executed'

    /pick:
        story: 'Choose steps to be executed'
        example:
            - tmt run provision prepare
            - tmt run discover provision prepare
        implemented: /tmt/base
    /until:
        story: 'Run all steps until the given one'
        example:
            - tmt run --until prepare
            - tmt run --until execute
        implemented: /tmt/base
    /since:
        story: 'Run all steps since the given one'
        example:
            - tmt run --since prepare
            - tmt run --since execute
        implemented: /tmt/base
    /skip:
        story: 'Skip given step during execution'
        example:
            - tmt run --skip prepare
            - tmt run --skip finish
        implemented: /tmt/base
    /all:
        story: 'Run all test steps, customize some'
        example:
            - tmt run --all provision --how=container
        implemented: /tmt/base

/interactive:
    story: 'Provide way similar to git rebase --interactive'
    description:
        Provide users with list of steps and let them edit them.
        Allow adding commands between, or at least interactive "pause".
        When user would be finished with single step, just continue recipe.
        Do not force users to remember all steps when working with them.
        Make it possible to repeat single step or abort current run.
        Allow repeating some steps just by repeating lines with task.
    example:
        - tmt run --all --interactive
        - tmt run --continue
        - tmt run --abort

/upgrade:
    story:
        As a tester I want to verify that a configured application
        or service still correctly works after the system upgrade.
    description: |
        In order to enable developing tests for upgrade testing we
        need to provide a way how to execute these tests easily.
        This does not cover unit tests for individual actors but
        rather system tests which verify the whole upgrade story.

        The plan is to provide an environment variable available
        to the test denoting current phase of the upgrade testing
        (``before`` or ``after`` the upgrade). Based on this
        variable test can perform appropriate actions.

        before
            setup, test
        after
            test, cleanup
        without
            setup, test, cleanup

        Combining test step selection feature and defining extra
        environment variables together with an external framework
        to perform the actual system upgrade should give us a nice
        way how to achieve the desired functionality. In addition,
        we will also need to implement a way how to aggregate test
        results from both runs (before and after the upgrade).
    example:
        - tmt run --id foo discover provision --image=rhel7 --output=box.json
        - tmt run --id foo execute --environment='UPGRADE=before'
        - upgrade-the-system box.json
        - tmt run --id foo execute --environment='UPGRADE=after'
        - tmt run --id foo report finish

/shortcuts:
    story: 'Provide shortcuts for common scenarios'
    /container:
        example:
            - tmt run --container=fedora:rawhide
            - tmt run --container=fedora:rawhide --cap-add=SYS_ADMIN
    /mock:
        example:
            - tmt --mock fedora-31-x86_64
            - tmt --mock fedora-31-x86_64 --no-clean --enable-network
            - tmt --mock fedora-31-x86_64 --enablerepo=updates-testing

/filter:
    /plan:
        story: 'Select plans for execution'
        example:
            - tmt run plan --name=NAME
            - tmt run plan --filter=FILTER
            - tmt run plan --condition=CONDITION
        implemented: /tmt/base.py
    /test:
        story: 'Select tests for execution'
        example:
            - tmt run test --name=NAME
            - tmt run test --filter=FILTER
            - tmt run test --condition=CONDITION
            - tmt run plan --name=NAME2 test --name=NAME1
        implemented: /tmt/base.py

/keep:
    story: Store test step status, keep machines running
    example:
        - tmt run --id ID provision prepare
        - tmt run --id ID discover execute
        - tmt run --id ID execute
        - tmt run --id ID execute
    implemented: /tmp/base.py

/debug:
    summary: Handsfree debugging
    story:
        As a test developer I want to automatically execute
        tests upon saving the updated test code to disk.
    example: tmt run debug

/smoke:
    story:
        As a developer I want to do a quick smoke test of my
        freshly built rpm package.
    example: |
        tmt run --all \
        prepare --artifact=tmt-0.4-1.fc29.noarch.rpm \
        execute --script='tmt --help'

/restraint:
    story:
        As a tester I want the option to execute tests using the
        Restraint harness.
    description:
        Restraint is the default harness in beaker for RHEL8 and
        beyond. In order to provide compatibility with beaker
        style tests, I would like a way to invoke ``tmt`` using
        the Restaint harness. This would enable Restraint tests to
        be invoked by ``tmt`` without modification. Some common
        commands include ``rstrnt-reboot``, ``rstrnt-abort``, and
        ``rstrnt-report-result``.
    example:
        - tmt run --all execute --how restraint

/last:
    story: 'As a user I want to rerun tests easily'
    description: >
        Execute previous run without the need to specify the
        previous run id. The command is a shortcut for::

            tmt run --id PREVIOUS_RUN

        Note that ``tmt`` saves last run id on each new execution.
    implemented: /tmt/base
    documented: /docs/examples#debug-tests
    example:
        - tmt run -l
        - tmt run --last

