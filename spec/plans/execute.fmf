summary: Define how tests should be executed

description: |
    Execute discovered tests in the provisioned environment using
    selected test executor. By default tests are executed using
    the internal ``tmt`` executor which allows to show detailed
    progress of the testing and supports interactive debugging.

    This is a **required** attribute. Each plan has to define this
    step.

    For each test, a separate directory is created for storing
    artifacts related to the test execution. Its path is
    constructed from the test name and it's stored under the
    ``execute/data`` directory. It contains a ``metadata.yaml``
    file with the aggregated L1 metadata which can be used by the
    test :ref:`/spec/tests/framework`. In addition to supported
    :ref:`/spec/tests` attributes it also contains fmf ``name`` of
    the test.

    For each ``plan`` the execute step must produce a
    ``results.yaml`` file with the list of results for each test
    in the following format::

        /test/one:
            result: OUTCOME
            log:
              - PATH

        /test/two:
            result: OUTCOME
            log:
              - PATH1
              - PATH2
            duration: DURATION

    Where ``OUTCOME`` is the result of the test execution. It can
    have the following values:

        pass
            Test execution successfully finished and passed.
        info
            Test finished but only produced an informational
            message. Represents a soft pass, used for skipped
            tests and for tests with the :ref:`/spec/tests/result`
            attribute set to *ignore*. Automation must treat
            this as a passed test.
        warn
            A problem appeared during test execution which does
            not affect test results but might be worth checking
            and fixing. For example test cleanup phase failed.
            Automation must treat this as a failed test.
        error
            Undefined problem encountered during test execution.
            Human inspection is needed to investigate whether it
            was a test bug, infrastructure error or a real test
            failure. Automation must treat it as a failed test.
        fail
            Test execution successfully finished and failed.

    ``PATH`` or each ``PATH*`` are the test log output paths,
    relative to the execute step working directory. ``log`` key
    is a list of strings, even when there is just a single log, the first
    log will be considered as the main one (e.g. presented to the
    user for inspection).

    The ``DURATION`` is an optional section stating how long did
    the test run. Its value is in the ``hh:mm:ss`` format.

/upgrade:
    summary: Perform system upgrades during testing
    story:
        As a tester I want to verify that a configured application
        or service still correctly works after the system upgrade.
    description: |
        In order to enable developing tests for upgrade testing, we
        need to provide a way how to execute these tests easily.
        This does not cover unit tests for individual actors but
        rather system tests which verify the whole upgrade story.

        The ``upgrade`` executor runs the discovered tests (using
        the internal executor, hence the same config options can
        be used), then performs a set of upgrade tasks from
        a remote repository, and finally, re-runs the tests on
        the upgraded system.

        The ``IN_PLACE_UPGRADE`` environment variable is set during
        the test execution to differentiate between the stages of
        the test. It is set to ``old`` during the first execution
        and ``new`` during the second execution. Test names are
        prefixed with this value to make the names unique.
        Based on this variable, the test can perform appropriate
        actions.

        old
            setup, test
        new
            test, cleanup
        without
            setup, test, cleanup

        The upgrade tasks performing the actual system upgrade are
        taken from a remote repository (specified by the ``url`` key)
        based on an upgrade path (specified by the ``upgrade-path`` key)
        or other filters (e.g. specified by the ``filter`` key).
        If both ``upgrade-path`` and extra filters are specified,
        the discover keys in the remote upgrade path plan are overridden
        by the filters specified in the local plan.

        The upgrade path must correspond to a plan name in the remote
        repository whose discover selects tests (upgrade tasks).
        The environment variables defined in the upgrade path are passed
        to the upgrade tasks.
    example:
      - |
        # Main testing plan
        discover:
            how: fmf
        execute:
            how: upgrade
            url: https://github.com/teemtee/upgrade
            upgrade-path: /paths/fedora35to36

      - |
        # Upgrade path /paths/fedora35to36.fmf in the remote repository
        discover: # Selects appropriate upgrade tasks (L1 tests)
            how: fmf
            filter: "tag:fedora"
        environment: # This is passed to upgrade tasks
            SOURCE: 35
            TARGET: 36
        execute:
            how: tmt

      - |
        # Alternative main testing plan, without upgrade path
        execute:
            how: upgrade
            url: https://github.com/teemtee/upgrade
            filter: "tag:fedora"

      - |
        # A simple beakerlib test using the $IN_PLACE_UPGRADE variable
        . /usr/share/beakerlib/beakerlib.sh || exit 1

        VENV_PATH=/var/tmp/venv_test

        rlJournalStart
            # Perform the setup only for the old distro
            if [[ "$IN_PLACE_UPGRADE" !=  "new" ]]; then
                rlPhaseStartSetup
                    rlRun "python3.9 -m venv $VENV_PATH"
                    rlRun "$VENV_PATH/bin/pip install pyjokes"
                rlPhaseEnd
            fi

            # Execute the test for both old & new distro
            rlPhaseStartTest
                rlAsssertExists "$VENV_PATH/bin/pyjoke"
                rlRun "$VENV_PATH/bin/pyjoke"
            rlPhaseEnd

            # Skip the cleanup phase when on the old distro
            if [[ "$IN_PLACE_UPGRADE" !=  "old" ]]; then
                rlPhaseStartCleanup
                    rlRun "rm -rf $VENV_PATH"
                rlPhaseEnd
            fi
        rlJournalEnd

    link:
      - implemented-by: /tmt/steps/execute/upgrade.py
      - verified-by: /tests/execute/upgrade


/isolate:
    summary: Run tests in an isolated environment
    description:
        Optional boolean attribute `isolate` can be used to
        request a clean test environment for each test.
    example: |
        execute:
            how: tmt
            isolate: true

/exit-first:
    summary: Stop execution after a test fails
    story:
        As a user I want to avoid waiting for all discovered
        tests to finish if one of them fails.
    description:
        Optional boolean attribute `exit-first` can be used to
        make the executor stop executing tests once a test
        failure is encountered.
    example: |
        execute:
            how: tmt
            exit-first: true
    link:
      - implemented-by: /tmt/steps/execute/internal.py
      - verified-by: /tests/execute/exit-first

/tmt:
    summary: Internal test executor
    story: As a user I want to execute tests directly from tmt.
    description: |
        The internal ``tmt`` executor runs tests in the
        provisioned environment one by one directly from the
        tmt code which allows features such as showing live
        :ref:`/stories/cli/steps/execute/progress` or the
        :ref:`/stories/cli/steps/execute/interactive` session .
        This is the default execute step implementation.

        The executor provides following shell scripts which can
        be used by the tests for certain operations.

        ``tmt-file-submit``
            Archive the given file in the tmt test data directory.
            See the :ref:`/stories/features/report-log` section
            for more details.

        ``tmt-reboot``
            Soft reboot the machine from inside the test. After reboot
            the execution starts from the test which rebooted the machine.
            An environment variable ``TMT_REBOOT_COUNT`` is provided which
            the test can use to handle the reboot. The variable holds the
            number of reboots performed by the test. For more information
            see the :ref:`/stories/features/reboot` feature documentation.

        ``tmt-report-result``
            Generate a result report file from inside the test. Can be
            called multiple times by the test. The generated report
            file will be overwritten if a higher hierarchical result is
            reported by the test. The hierarchy is as follows:
            SKIP, PASS, WARN, FAIL.
            For more information see the
            :ref:`/stories/features/report-result` feature documentation.

        ``tmt-abort``
            Generate an abort file from inside the test. This will
            set the current test result to failed and terminate
            the execution of subsequent tests.
            For more information see the
            :ref:`/stories/features/abort` feature documentation.

    example: |
        execute:
            how: tmt
    link:
      - implemented-by: /tmt/steps/execute/internal.py
      - verified-by: /tests/execute/framework

/script:
    summary: Execute shell scripts
    story: As a user I want to easily run shell script as a test.
    description: |
        Execute arbitratry shell commands and check their exit
        code which is used as a test result. The ``script`` field
        is provided to cover simple test use cases only and must
        not be combined with the :ref:`/spec/plans/discover` step
        which is more suitable for more complex test scenarios.

        Default shell options are applied to the script, see
        :ref:`/spec/tests/test` for more details. The default
        :ref:`/spec/tests/duration` for tests defined directly
        under the execute step is ``1h``. Use the ``duration``
        attribute to modify the default limit.

    example:
      - |
        # Run a simple smoke test
        execute:
            how: tmt
            script: tmt --help
      - |
        # Modify the default maximum duration
        execute:
            how: tmt
            script: a-long-test-suite
            duration: 3h
    link:
      - implemented-by: /tmt/steps/execute/internal.py

    /simple:
        summary: Simple use case should be super simple to write
        title: The simplest usage
        description: |
            As the `how` keyword can be omitted when using the
            default executor you can just define the shell
            `script` to be run. This is how a minimal smoke test
            configuration for the `tmt` command can look like:
        example: |
            execute:
                script: tmt --help

    /several:
        summary: Multiple shell commands
        title: Multiple commands
        description:
            You can also include several commands as a list.
            Executor will run commands one-by-one and check exit
            code of each.
        example: |
            execute:
                script:
                  - dnf -y install httpd curl
                  - systemctl start httpd
                  - echo foo > /var/www/html/index.html
                  - curl http://localhost/ | grep foo

    /multi:
        summary: Multi-line shell script
        title: Multi-line script
        description:
            Providing a multi-line shell script is also supported.
            Note that the first command with non-zero exit code
            will finish the execution. See the
            :ref:`/spec/tests/test` key for details about default
            shell options.
        example: |
            execute:
                script: |
                    dnf -y install httpd curl
                    systemctl start httpd
                    echo foo > /var/www/html/index.html
                    curl http://localhost/ | grep foo
